# -*- coding: utf-8 -*-
"""PCA+Logistic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/157_9pyENH3Ita7ez6wyJUKDOSS_diFtS
"""

import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, f1_score
import time

dftrain = pd.read_csv('/content/MNIST_train.csv')
dfval = pd.read_csv('/content/MNIST_validation.csv')

dftrain = dftrain.drop('even', axis=1)

dfval = dfval.drop('even', axis=1)

featurecols = list(dftrain.columns)
targetcol = 'label'
featurecols.remove(targetcol)

print('length of featurecolumns is', len(featurecols))

Xtrain = np.array(dftrain[featurecols]) / 255
ytrain = np.array(dftrain[targetcol])

Xval = np.array(dfval[featurecols]) / 255
yval = np.array(dfval[targetcol])

class PCAModel:
    def __init__(self, n_components):
        self.n_components = n_components
        self.mean = None
        self.components = None
        self.explained_variance = None

    def fit(self, X):
        X = np.array(X, dtype=float)

        self.mean = np.mean(X, axis=0)
        X_centered = X - self.mean

        cov_matrix = np.cov(X_centered, rowvar=False)
        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)

        sorted_idx = np.argsort(eigenvalues)[::-1]

        self.explained_variance = eigenvalues[sorted_idx][:self.n_components]
        self.components = eigenvectors[:, sorted_idx][:, :self.n_components]

    def predict(self, X):
        if self.mean is None:
            raise ValueError("PCA is not fitted yet.")

        X_centered = X - self.mean
        return np.dot(X_centered, self.components)

    def reconstruct(self, X):
        Z = self.predict(X)
        return np.dot(Z, self.components.T) + self.mean

class SoftmaxRegression:
    def __init__(self, learning_rate=0.1, epochs=1000):
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.W = None
        self.b = None

    def _softmax(self, z):
        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))
        return exp_z / np.sum(exp_z, axis=1, keepdims=True)

    def _one_hot(self, y, num_classes):
        return np.eye(num_classes)[y]

    def _cross_entropy_loss(self, y_true, y_pred):
        return -np.mean(np.sum(y_true * np.log(y_pred + 1e-15), axis=1))

    def fit(self, X, y):
        num_samples, num_features = X.shape
        num_classes = np.max(y) + 1

        self.W = np.random.randn(num_features, num_classes) * 0.01
        self.b = np.zeros((1, num_classes))

        Y_onehot = self._one_hot(y, num_classes)

        for epoch in range(self.epochs):
            logits = np.dot(X, self.W) + self.b
            probs = self._softmax(logits)
            loss = self._cross_entropy_loss(Y_onehot, probs)

            grad_logits = (1. / num_samples) * (Y_onehot - probs)
            grad_W = -np.dot(X.T, grad_logits)
            grad_b = -np.sum(grad_logits, axis=0, keepdims=True)

            self.W -= self.learning_rate * grad_W
            self.b -= self.learning_rate * grad_b

            if epoch % 100 == 0:
                print(f"Epoch {epoch}: Loss = {loss:.4f}")

    def predict_proba(self, X):
        logits = np.dot(X, self.W) + self.b
        return self._softmax(logits)

    def predict(self, X):
        probs = self.predict_proba(X)
        return np.argmax(probs, axis=1)

n_components = 100
pca = PCAModel(n_components=n_components)

print("\nFitting PCA...")
pca.fit(Xtrain)

Xtrain_pca = pca.predict(Xtrain)
Xval_pca = pca.predict(Xval)

print("Shape after PCA:", Xtrain_pca.shape)
epochs = 1000
lr = 0.1

model = SoftmaxRegression(learning_rate=lr, epochs=epochs)

print("\nTraining Softmax Regression...")
start = time.time()
model.fit(Xtrain_pca, ytrain)
end = time.time()

print(f"\nTraining time: {end - start:.2f} seconds")

ypred_train = model.predict(Xtrain_pca)
ypred_test = model.predict(Xval_pca)
train_acc = accuracy_score(ytrain, ypred_train)
val_acc = accuracy_score(yval, ypred_test)

train_f1 = f1_score(ytrain, ypred_train, average='weighted')
val_f1 = f1_score(yval, ypred_test, average='weighted')

print("\n----------------------------")
print("PCA + Softmax Regression RESULTS")
print("----------------------------")
print("Train Accuracy:", train_acc)
print("Valdation Accuracy:", val_acc)
print("Train F1:", train_f1)
print("Validation F1:", val_f1)

"""Hypertuning Parameters"""

Components = [600,500,400,300,200,100,50]

for c in Components:
    n_components = c
    print("\n====================================")
    print("Number of components:", n_components)
    print("====================================")

    pca_c = PCAModel(n_components=n_components)
    print("\nFitting PCA...")
    pca_c.fit(Xtrain)

    Xtrain_pca_c = pca_c.predict(Xtrain)
    Xval_pca_c = pca_c.predict(Xval)

    print("Shape after PCA:", Xtrain_pca_c.shape)

    epochs = 1000
    lr = 0.1

    model_c = SoftmaxRegression(learning_rate=lr, epochs=epochs)

    print("\nTraining Softmax Regression...")
    start = time.time()
    model_c.fit(Xtrain_pca_c, ytrain)
    end = time.time()
    print(f"\nTraining time: {end - start:.2f} seconds")

    ypred_train_c = model_c.predict(Xtrain_pca_c)
    ypred_val_c = model_c.predict(Xval_pca_c)

    train_acc_c = accuracy_score(ytrain, ypred_train_c)
    val_acc_c   = accuracy_score(yval, ypred_val_c)

    train_f1_c = f1_score(ytrain, ypred_train_c, average='weighted')
    val_f1_c   = f1_score(yval, ypred_val_c,  average='weighted')

    print("\n----------------------------")
    print("PCA + Softmax Regression RESULTS")
    print("----------------------------")
    print("Train Accuracy:", train_acc_c)
    print("Validation Accuracy:", val_acc_c)
    print("Train F1:", train_f1_c)
    print("Validation F1:", val_f1_c)

n_components = 100
pca = PCAModel(n_components=n_components)

print("\nFitting PCA...")
pca.fit(Xtrain)

Xtrain_pca = pca.predict(Xtrain)
Xval_pca = pca.predict(Xval)

print("Shape after PCA:", Xtrain_pca.shape)

n_epochs = [100, 200, 500, 1000, 2000]
lr = 0.1

for e in n_epochs:
    print("\n==============================")
    print(f"Running epochs = {e}")
    print("==============================")

    model_e = SoftmaxRegression(learning_rate=lr, epochs=e)

    print("\nTraining Softmax Regression...")
    start = time.time()
    model_e.fit(Xtrain_pca, ytrain)
    end = time.time()

    print(f"\nTraining time: {end - start:.2f} seconds")

    ypred_train_e = model_e.predict(Xtrain_pca)
    ypred_val_e   = model_e.predict(Xval_pca)

    train_acc_e = accuracy_score(ytrain, ypred_train_e)
    val_acc_e   = accuracy_score(yval, ypred_val_e)

    train_f1_e = f1_score(ytrain, ypred_train_e, average='weighted')
    val_f1_e   = f1_score(yval, ypred_val_e, average='weighted')

    print("\n----------------------------")
    print("PCA + Softmax Regression RESULTS")
    print("----------------------------")
    print("Train Accuracy:", train_acc_e)
    print("Validation Accuracy:", val_acc_e)
    print("Train F1:", train_f1_e)
    print("Validation F1:", val_f1_e)

n_components = 100
pca = PCAModel(n_components=n_components)

print("\nFitting PCA...")
pca.fit(Xtrain)

Xtrain_pca = pca.predict(Xtrain)
Xval_pca = pca.predict(Xval)

print("Shape after PCA:", Xtrain_pca.shape)

n_epochs = 1000
learnr = [0.01, 0.02, 0.1, 0.2]

for l in learnr:
    print("\n==============================")
    print(f"Running learning rate = {l}")
    print("==============================")

    model_l = SoftmaxRegression(learning_rate=l, epochs=n_epochs)

    print("\nTraining Softmax Regression...")
    start = time.time()
    model_l.fit(Xtrain_pca, ytrain)
    end = time.time()

    print(f"\nTraining time: {end - start:.2f} seconds")

    ypred_train_l = model_l.predict(Xtrain_pca)
    ypred_val_l   = model_l.predict(Xval_pca)

    train_acc_l = accuracy_score(ytrain, ypred_train_l)
    val_acc_l   = accuracy_score(yval, ypred_val_l)

    train_f1_l = f1_score(ytrain, ypred_train_l, average='weighted')
    val_f1_l   = f1_score(yval, ypred_val_l, average='weighted')

    print("\n----------------------------")
    print("PCA + Softmax Regression RESULTS")
    print("----------------------------")
    print("Train Accuracy:", train_acc_l)
    print("Validation Accuracy:", val_acc_l)
    print("Train F1:", train_f1_l)
    print("Validation F1:", val_f1_l)

n_components = 100
pca_best = PCAModel(n_components=n_components)

print("\nFitting PCA...")
pca_best.fit(Xtrain)

Xtrain_pca_best = pca_best.predict(Xtrain)
Xval_pca_best = pca_best.predict(Xval)

print("Shape after PCA:", Xtrain_pca_best.shape)

n_epochs_best = 2000
learnr_best = 0.2

print("\n==============================")
print(f"Running learning rate = {learnr_best}")
print("==============================")

model_best = SoftmaxRegression(learning_rate=learnr_best, epochs=n_epochs_best)

print("\nTraining Softmax Regression...")
start = time.time()
model_best.fit(Xtrain_pca_best, ytrain)
end = time.time()

print(f"\nTraining time: {end - start:.2f} seconds")

ypred_train_best = model_best.predict(Xtrain_pca_best)
ypred_val_best   = model_best.predict(Xval_pca_best)

train_acc_best = accuracy_score(ytrain, ypred_train_best)
val_acc_best   = accuracy_score(yval, ypred_val_best)

train_f1_best = f1_score(ytrain, ypred_train_best, average='weighted')
val_f1_best   = f1_score(yval, ypred_val_best, average='weighted')

print("\n----------------------------")
print("PCA + Softmax Regression RESULTS")
print("----------------------------")
print("Train Accuracy:", train_acc_best)
print("Validation Accuracy:", val_acc_best)
print("Train F1:", train_f1_best)
print("Validation F1:", val_f1_best)